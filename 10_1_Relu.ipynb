{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeCl5kEwP6WAru5CiQz2X4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jake0925/DeepLearning/blob/master/10_1_Relu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simoid\n",
        "레이어층이 많지만 경우 학습이 잘되지 않는다\n",
        "\n",
        "-> sigmoid은 문제점 발견됨\n",
        "\n",
        "-> 0과 1사이의 너무 작은값을 갖기때문에 문제가 발생함"
      ],
      "metadata": {
        "id": "ocRIwUYb6Vg_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR0Ru61938Qc",
        "outputId": "4530eafb-1ae5-4cae-848c-868ad808c25d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 5)                 15        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231 (924.00 Byte)\n",
            "Trainable params: 231 (924.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "tf.model = tf.keras.Sequential()\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, input_dim=2, activation='sigmoid')) # layer1, 출력개수는 원하는데로 설정하고 여러개를 설정하였으므로 wide하다\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='sigmoid')) # layer, layer1의 출력갯수와 layer2의 입력개수는 동일해야한다\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='sigmoid')) # layer3\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='sigmoid')) # layer4\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='sigmoid')) # layer5\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='sigmoid')) # layer6\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='sigmoid')) # layer7\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='sigmoid')) # layer8\n",
        "tf.model.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # layer9, 층이 여러개 이이므로 신경망이 깊다고 할수있다\n",
        "\n",
        "# SGD not working very well due to vanishing gradient problem, switched to Adam for now\n",
        "# or you may use activation='relu', study chapter 10 to know more on vanishing gradient problem.\n",
        "tf.model.compile(loss='binary_crossentropy', optimizer=tf.optimizers.Adam(lr=0.1), metrics=['accuracy'])\n",
        "tf.model.summary()\n",
        "\n",
        "log_dir = os.path.join(\".\", \"logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# 텐서콜백함수 정의\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=log_dir,  # 로그파일 기록 될 위치\n",
        "        histogram_freq=1,  # 1에포크마다 활성화 출력의 히스토그램을 기록\n",
        "        embeddings_freq=1,  # 1에포크마다 임베딩 데이터를 기록\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = tf.model.fit(x_data, y_data, epochs=100, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EFktaXeD4yZ6",
        "outputId": "42a63e1d-cc00-4055-aae6-006a0828d2f6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.6931 - accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = tf.model.predict(x_data)\n",
        "print('Prediction: \\n', predictions)\n",
        "\n",
        "# 매우 정확해짐\n",
        "score = tf.model.evaluate(x_data, y_data)\n",
        "print('Accuracy: ', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQQ39byX49Wr",
        "outputId": "ad7f48cd-9769-4f77-bf8b-1f1ea91dca94"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 157ms/step\n",
            "Prediction: \n",
            " [[0.5000041]\n",
            " [0.4999629]\n",
            " [0.5000512]\n",
            " [0.4999872]]\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Accuracy:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relu\n",
        "위의 문제점을 개선하기 위해 relu가 도입됨\n",
        "\n",
        "그러나 맨마지막 layer의 경우 결과가 0과 1이어야 하기 때문에 sigmoid를 사용해야 한다"
      ],
      "metadata": {
        "id": "lPSgQSvK2ndh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "tf.model = tf.keras.Sequential()\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, input_dim=2, activation='relu')) # layer1, 출력개수는 원하는데로 설정하고 여러개를 설정하였으므로 wide하다\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='relu')) # layer, layer1의 출력갯수와 layer2의 입력개수는 동일해야한다\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='relu')) # layer3\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='relu')) # layer4\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='relu')) # layer5\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='relu')) # layer6\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='relu')) # layer7\n",
        "tf.model.add(tf.keras.layers.Dense(units=5, activation='relu')) # layer8\n",
        "tf.model.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # layer9, 층이 여러개 이이므로 신경망이 깊다고 할수있다\n",
        "\n",
        "# SGD not working very well due to vanishing gradient problem, switched to Adam for now\n",
        "# or you may use activation='relu', study chapter 10 to know more on vanishing gradient problem.\n",
        "tf.model.compile(loss='binary_crossentropy', optimizer=tf.optimizers.Adam(lr=0.1), metrics=['accuracy'])\n",
        "tf.model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtWiFTA122fj",
        "outputId": "76185b99-a158-476c-8bcd-a4c041ad2df6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 5)                 15        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231 (924.00 Byte)\n",
            "Trainable params: 231 (924.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = tf.model.fit(x_data, y_data, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XJWGVSAU4_sa",
        "outputId": "f76860b6-3a42-4712-a48f-796bfcf4624d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6956 - accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6946 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6927 - accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6918 - accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6910 - accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6908 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6905 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6900 - accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6893 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6890 - accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6888 - accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6885 - accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6882 - accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6879 - accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6877 - accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6874 - accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6871 - accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6868 - accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6864 - accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6862 - accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6856 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6853 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6849 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6846 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6844 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6841 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6840 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6837 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6834 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6831 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6828 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6825 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6822 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6818 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6815 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6812 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6809 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6805 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6802 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6798 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6794 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6790 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6786 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6781 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6777 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6773 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6768 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6764 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6759 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6754 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6750 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6744 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6739 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6734 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6728 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6722 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6717 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6711 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6705 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6699 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6693 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6686 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6680 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6673 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6666 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6660 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6652 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6643 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6636 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6628 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6621 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6611 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6602 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6593 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6583 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6573 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6563 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6552 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6541 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6530 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6519 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6506 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6493 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6481 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6468 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6455 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6442 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6427 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6414 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6400 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6385 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6370 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6355 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6339 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6323 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6309 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = tf.model.predict(x_data)\n",
        "print('Prediction: \\n', predictions)\n",
        "\n",
        "# 매우 정확해짐\n",
        "score = tf.model.evaluate(x_data, y_data)\n",
        "print('Accuracy: ', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv6p-UBP4_p2",
        "outputId": "65021051-f7c8-4d1d-ab98-3ebeb4f983a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 153ms/step\n",
            "Prediction: \n",
            " [[0.47978032]\n",
            " [0.5710515 ]\n",
            " [0.51660264]\n",
            " [0.47393814]]\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.6291 - accuracy: 1.0000\n",
            "Accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NF8b95x54_m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a-qzTXzy4_kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dSopwp3B4_hl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}